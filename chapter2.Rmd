<<<<<<< HEAD
# Maarit Tarkiainen 11 Nov Linear regression analyses
```{r child = "chapter2.Rmd"}```


install.packages("ggplot2")
This library is needed to produce good sophisticated pictures
```{r}
library(ggplot2)
```
This will read the data and name it "learning2014"
``` {r}
learning2014<-read.table("/Users/maarit/IODS-project/data/learning2014")
```
This will show the structure of the data "learning2014"

```{r}
str(learning2014) 
``` 
To see a summery of the variables in "learning2014"

summary (learning2014)
```
To access the GGally and ggplot2 libraries needed in sophisticated plots
install.packages("GGally")
```{r}
library(GGally)
library(ggplot2)
```
To explore the relationship of variables to one another, the following codes will produce a plot matrix
```{r}
pairs (learning2014)
```

```{r}
p <- ggpairs(learning2014, mapping = aes(col=gender, alpha=0.3), lower = list(combo = wrap("facethist", bins = 20)))
p
```
This picture shows correlations of all variables to each other, one by one. Both genders have been presented separately. #Age has the most non-normal distribution, with skewness to right.Attitude, surf and strategic questions show biggest difference between genders.
```{r}
my_model <- lm(Points ~ Attitude + stra + surf, data = learning2014)
summary(my_model)
```
The only factor in this model that has a significant p-value is Attitude. Thus, the exploration continues.
```{r}
my_model2 <- lm(Points ~ Attitude + Age + deep, data = learning2014)
summary(my_model2)
```
Also in this model, only Attitude is significant

```{r}
my_model5 <- lm(Points ~ Attitude + stra, data = learning2014)
summary(my_model5)
```
The adjusted R square of this model is 0.1951, meaning that 19.5% of the change in points is explained by the variables in the model. It means that the model is not very good in explaning the variation in the test variable points.
Coefficient estimate 0.34658 shows the change in Points when Attitude changes 1 unit.
Let's allow R print 4 different plot on same page
And print residuals vs fitted, Normal QQ-plot, and Residuals vs Leverage to test the assumptions of the model:
```{r}
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))
plot(my_model5, which = c(1,2,5)) 
```
The plots show that the residuals of the model are close to normally distributed.